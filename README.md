# Sistema RAG para DocumentaciÃ³n de Seguros Allianz

Este proyecto implementa un sistema de RecuperaciÃ³n Aumentada de GeneraciÃ³n (RAG) para procesar y consultar documentaciÃ³n de seguros utilizando Llama 2 y una base de datos vectorial.

## ğŸ—ï¸ Estructura del Proyecto

```
.
â”œâ”€â”€ data/                    # Directorio para documentos PDF y TXT
â”œâ”€â”€ loader.py               # Procesador de documentos y creaciÃ³n de Ã­ndices
â”œâ”€â”€ RAG.py                 # Sistema RAG principal
â”œâ”€â”€ db_viewer.py           # Visualizador web de la base de datos vectorial
â”œâ”€â”€ test_llama.py          # Script de prueba para el modelo Llama 2
â””â”€â”€ requirements.txt       # Dependencias del proyecto
```

## ğŸ“‹ Requisitos

1. Python 3.8+
2. Modelo Llama 2: `llama-2-7b-chat.q4_k_m.gguf`
3. Dependencias Python listadas en `requirements.txt`

## ğŸš€ InstalaciÃ³n

1. Clonar el repositorio:
```bash
git clone [url-del-repositorio]
cd [nombre-del-repositorio]
```

2. Crear y activar entorno virtual:
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\\Scripts\\activate   # Windows
```

3. Instalar dependencias:
```bash
pip install -r requirements.txt
```

4. Descargar el modelo Llama 2:
- Asegurarse de tener el archivo `llama-2-7b-chat.q4_k_m.gguf` en el directorio raÃ­z

## ğŸ’¾ PreparaciÃ³n de Datos

1. Colocar los documentos PDF/TXT en la carpeta `data/`
2. Ejecutar el procesador de documentos:
```bash
python loader.py
```

## ğŸ” Uso del Sistema

### Visualizar Base de Datos
```bash
streamlit run db_viewer.py
```
- Ver todos los fragmentos indexados
- Realizar bÃºsquedas semÃ¡nticas
- Explorar el contenido procesado

### Usar el Sistema RAG
```bash
python RAG.py
```
- Hacer preguntas sobre la documentaciÃ³n
- Obtener respuestas basadas en el contexto
- Interactuar con el modelo Llama 2

### Probar el Modelo
```bash
python test_llama.py
```
- Verificar el funcionamiento bÃ¡sico del modelo
- Realizar pruebas simples de generaciÃ³n

## ğŸ”„ Flujo de Trabajo

1. **Procesamiento de Documentos** (`loader.py`):
   - Carga documentos PDF/TXT
   - Divide en secciones relevantes
   - Genera embeddings
   - Crea Ã­ndice vectorial FAISS

2. **Base de Datos Vectorial**:
   - Almacena fragmentos de texto
   - Mantiene Ã­ndices para bÃºsqueda rÃ¡pida
   - Permite bÃºsquedas semÃ¡nticas

3. **Sistema RAG** (`RAG.py`):
   - Recibe preguntas del usuario
   - Busca contexto relevante
   - Genera respuestas usando Llama 2

## ğŸ“Š Componentes Principales

### Loader (`loader.py`)
- Clase `DocumentProcessor`
- Manejo de mÃºltiples formatos
- Procesamiento de texto inteligente
- GeneraciÃ³n de embeddings

### RAG (`RAG.py`)
- Clase `RAGSimple`
- IntegraciÃ³n con Llama 2
- BÃºsqueda de contexto
- GeneraciÃ³n de respuestas

### Visualizador (`db_viewer.py`)
- Interfaz web con Streamlit
- ExploraciÃ³n de datos
- BÃºsqueda semÃ¡ntica
- VisualizaciÃ³n de fragmentos

## ğŸ› ï¸ ConfiguraciÃ³n

- Modelo: CPU por defecto (cambiar `gpu_layers=0` para GPU)
- Contexto: 2048 tokens mÃ¡ximo
- Threads: 4 (ajustable segÃºn CPU)
- Fragmentos: ~1000 caracteres por secciÃ³n

## ğŸ“ Notas

- Los documentos deben estar en la carpeta `data/`
- El modelo Llama 2 debe estar en el directorio raÃ­z
- Se recomienda usar GPU para mejor rendimiento
- La base de datos vectorial se actualiza al procesar nuevos documentos

## ğŸ¤ ContribuciÃ³n

1. Fork el repositorio
2. Crea una rama para tu feature
3. Commit tus cambios
4. Push a la rama
5. Crea un Pull Request

## ğŸ“„ Licencia

Este proyecto es privado y para uso interno. 